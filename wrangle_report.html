<!doctype html>
<head>
    <title>Wrangle Report</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js"></script>
</head>
<body>
    <div class="container">
        <div class="card">
            <div class="card-header">Introduction</div>
            <div class="card-body">
                <p>
                    This project talks about Data Wrangling that involves three distinct
                    steps that can be revisited anytime; i.e. it is iterative if your
                    needs are not met. The three steps are:
                    <ol>
                        <li>Gathering</li>
                        <li>Assessing</li>
                        <li>Cleaning</li>
                    </ol>
                </p>
            </div>
            <div class="card-footer">
                <p>
                    Personally this project was the longest that I had ever worked on, it
                    took me like 10 days to finish this, the delays was because of the
                    application for accessing Twitter.
                </p>
            </div>
        </div>
        <br/>
        <div class="card-header">Challenges</div>
        <div class="card-body">
            <p>The following were the issues that I had to over come.</p>
            <div class="card-deck">
                <div class="card">
                    <h4>Gathering</h4>
                    <ul>
                        <li>
                            Querying the API was bit trouble some as on an average it took 30
                            mins to fetch data.
                        </li>
                        <li>
                            Querying the API for missing records. I thought that there was
                            something wrong with my code, so I redid the entire thing, but later
                            I found that there was nothing wrong with the code.
                        </li>
                    </ul>
                </div>
                <div class="card">
                    <h4>Assessing</h4>
                    <ul>
                        <li>
                            This was easy, it took about an hour or so find falts and criticise
                            it for all the mess it was in.
                        </li>
                        <li>
                            Although, assessing the image-predictions.tvs file was a bit
                            overwhelming as there was nothing wrong in it, until programmatic
                            was done.
                        </li>
                    </ul>
                </div>
                <div class="card">
                    <h4>Cleaning</h4>
                    <ul>
                        <li>
                            Well, this was the longest of all processes. Properly defining the
                            cleaning goals initial was tough, but it all got easy after two
                            attempts.
                        </li>
                        <li>
                            Another challenge that I had to encounter was defining the regular
                            expressions for extracting name from text, and to find those that 
                            were missed by regexs'.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="card-footer">
            <h4>Overall Experience</h4>
            <p>
                Well, this one will teach you to learn the importance of cleaning data
                before we start building model or performing EDA. Not only cleaning, as
                well in gathering and assessing.
            </p>
            <p>
                It is strongly recommended that every individual must take a refresher
                course in python and pandas, after all you get used with R's syntax and
                it ability to handle undity data with the help from 'tidyverse' package.
            </p>
        </div>
    </div>
</body>