{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Dataset - WeRateDogs&trade; Twitter Archive\n",
    "\n",
    "***By Kartik Nanduri***<br>\n",
    "**Dated: 21st Nov, 2018.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] **The file given at hand `twitter-archive-enhanced.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the requried files for this project are in the list files_list\n",
    "files_list = ['twitter-archive-enhanced.csv', 'image-predictions.tsv', 'tweet_json.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>825876512159186944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-30 01:21:19 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Mo. No one will push him around in the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/825876512...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>Mo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>706265994973601792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-05 23:51:49 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Kara. She's been trying to solve that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/706265994...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>Kara</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>803638050916102144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-29 16:33:36 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Pupper hath acquire enemy. 13/10 https://t.co/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/803638050...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pupper</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>762471784394268675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-08 02:13:34 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Meet Glenn. Being in public scares him. Fright...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/762471784...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Glenn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>855818117272018944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-22 16:18:34 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>I HEARD HE TIED HIS OWN BOWTIE MARK AND HE JUS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/markhalperin/status/855656...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "393   825876512159186944                    NaN                  NaN   \n",
       "1323  706265994973601792                    NaN                  NaN   \n",
       "556   803638050916102144                    NaN                  NaN   \n",
       "863   762471784394268675                    NaN                  NaN   \n",
       "192   855818117272018944                    NaN                  NaN   \n",
       "\n",
       "                      timestamp  \\\n",
       "393   2017-01-30 01:21:19 +0000   \n",
       "1323  2016-03-05 23:51:49 +0000   \n",
       "556   2016-11-29 16:33:36 +0000   \n",
       "863   2016-08-08 02:13:34 +0000   \n",
       "192   2017-04-22 16:18:34 +0000   \n",
       "\n",
       "                                                 source  \\\n",
       "393   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1323  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "556   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "863   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "192   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                   text  retweeted_status_id  \\\n",
       "393   This is Mo. No one will push him around in the...                  NaN   \n",
       "1323  This is Kara. She's been trying to solve that ...                  NaN   \n",
       "556   Pupper hath acquire enemy. 13/10 https://t.co/...                  NaN   \n",
       "863   Meet Glenn. Being in public scares him. Fright...                  NaN   \n",
       "192   I HEARD HE TIED HIS OWN BOWTIE MARK AND HE JUS...                  NaN   \n",
       "\n",
       "      retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "393                        NaN                        NaN   \n",
       "1323                       NaN                        NaN   \n",
       "556                        NaN                        NaN   \n",
       "863                        NaN                        NaN   \n",
       "192                        NaN                        NaN   \n",
       "\n",
       "                                          expanded_urls  rating_numerator  \\\n",
       "393   https://twitter.com/dog_rates/status/825876512...                11   \n",
       "1323  https://twitter.com/dog_rates/status/706265994...                11   \n",
       "556   https://twitter.com/dog_rates/status/803638050...                13   \n",
       "863   https://twitter.com/dog_rates/status/762471784...                12   \n",
       "192   https://twitter.com/markhalperin/status/855656...                13   \n",
       "\n",
       "      rating_denominator   name doggo floofer  pupper puppo  \n",
       "393                   10     Mo  None    None    None  None  \n",
       "1323                  10   Kara  None    None    None  None  \n",
       "556                   10   None  None    None  pupper  None  \n",
       "863                   10  Glenn  None    None    None  None  \n",
       "192                   10   None  None    None    None  None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the twitter archive file\n",
    "archive = pd.read_csv(files_list[0])\n",
    "\n",
    "# taking at random file entries for the archive file\n",
    "archive.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [x] **Fetching the data from url and saving it to local drive - `image-predictions.tsv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file from internet using the requests library\n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "res = req.get(url)\n",
    "\n",
    "with open(url.split('/')[-1], mode = \"wb\") as op_file:\n",
    "    op_file.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>769695466921623552</td>\n",
       "      <td>https://pbs.twimg.com/media/Cq6B8V6XYAA1T1R.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>pug</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>True</td>\n",
       "      <td>muzzle</td>\n",
       "      <td>0.165638</td>\n",
       "      <td>False</td>\n",
       "      <td>kuvasz</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>677228873407442944</td>\n",
       "      <td>https://pbs.twimg.com/media/CWYAEINW4AIuw8P.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>common_iguana</td>\n",
       "      <td>0.566338</td>\n",
       "      <td>False</td>\n",
       "      <td>tennis_ball</td>\n",
       "      <td>0.154646</td>\n",
       "      <td>False</td>\n",
       "      <td>green_lizard</td>\n",
       "      <td>0.044976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>676098748976615425</td>\n",
       "      <td>https://pbs.twimg.com/media/CWH8L72UkAAvjql.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>walking_stick</td>\n",
       "      <td>0.162179</td>\n",
       "      <td>False</td>\n",
       "      <td>sandal</td>\n",
       "      <td>0.129086</td>\n",
       "      <td>False</td>\n",
       "      <td>purse</td>\n",
       "      <td>0.081412</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>668537837512433665</td>\n",
       "      <td>https://pbs.twimg.com/media/CUcfnWlWsAAzlwE.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Lakeland_terrier</td>\n",
       "      <td>0.372988</td>\n",
       "      <td>True</td>\n",
       "      <td>toy_poodle</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>True</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.189737</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>676948236477857792</td>\n",
       "      <td>https://pbs.twimg.com/media/CWUA1GFW4AAowiq.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>guenon</td>\n",
       "      <td>0.611603</td>\n",
       "      <td>False</td>\n",
       "      <td>macaque</td>\n",
       "      <td>0.135176</td>\n",
       "      <td>False</td>\n",
       "      <td>squirrel_monkey</td>\n",
       "      <td>0.083247</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                          jpg_url  \\\n",
       "1404  769695466921623552  https://pbs.twimg.com/media/Cq6B8V6XYAA1T1R.jpg   \n",
       "542   677228873407442944  https://pbs.twimg.com/media/CWYAEINW4AIuw8P.jpg   \n",
       "508   676098748976615425  https://pbs.twimg.com/media/CWH8L72UkAAvjql.jpg   \n",
       "138   668537837512433665  https://pbs.twimg.com/media/CUcfnWlWsAAzlwE.jpg   \n",
       "537   676948236477857792  https://pbs.twimg.com/media/CWUA1GFW4AAowiq.jpg   \n",
       "\n",
       "      img_num                p1   p1_conf  p1_dog           p2   p2_conf  \\\n",
       "1404        1               pug  0.407117    True       muzzle  0.165638   \n",
       "542         1     common_iguana  0.566338   False  tennis_ball  0.154646   \n",
       "508         1     walking_stick  0.162179   False       sandal  0.129086   \n",
       "138         1  Lakeland_terrier  0.372988    True   toy_poodle  0.250445   \n",
       "537         1            guenon  0.611603   False      macaque  0.135176   \n",
       "\n",
       "      p2_dog               p3   p3_conf  p3_dog  \n",
       "1404   False           kuvasz  0.045837    True  \n",
       "542    False     green_lizard  0.044976   False  \n",
       "508    False            purse  0.081412   False  \n",
       "138     True        Chihuahua  0.189737    True  \n",
       "537    False  squirrel_monkey  0.083247   False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if fetched the data right way\n",
    "img_pre_test = pd.read_csv(files_list[1], delimiter = \"\\t\", encoding = 'utf-8')\n",
    "img_pre_test.sample(5)\n",
    "\n",
    "# we did it the right way, Yay! it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [x] **Getting data from Twitter&trade;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries for accessing Twitter via API\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up all the necessary placeholders for API\n",
    "consumer_key = 'xxx.xxx.xxx'\n",
    "consumer_secret = 'xxx.xxx.xxx'\n",
    "access_token = 'xxx.xxx.xxx'\n",
    "access_secret = 'xxx.xxx.xxx'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth_handler = auth,\n",
    "                 parser = tweepy.parsers.JSONParser(),\n",
    "                 wait_on_rate_limit = True, \n",
    "                 wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save(ids, api_ins, one_id = None):\n",
    "    '''\n",
    "    This function will fetch data with associated id in ids list\n",
    "    ids (List Object): a list all tweets\n",
    "    api_ins (Tweepy Object): api object instance, will be used to query twitter for data\n",
    "    one_id (int): use when you want to query only for one tweet\n",
    "    failed_ids (List Object): a list will be retured so that, this fuction can be called once again on those ids\n",
    "    '''\n",
    "    new_file_name = ''; failed_ids = []\n",
    "    \n",
    "    # checking if file exists\n",
    "    if os.path.exists(files_list[2]):\n",
    "        temp = [s for s in os.listdir() if \"tweet_json\" in s]\n",
    "        new_file_name = files_list[2].split('.')[0] + \"_\" + str(len(temp)) + \".txt\"\n",
    "    else:\n",
    "        new_file_name = files_list[2]\n",
    "    \n",
    "    # querying a list of ids\n",
    "    if one_id == None:\n",
    "        with open(new_file_name, mode = 'w') as outfile:\n",
    "            for one_id in ids:\n",
    "                try:\n",
    "                    page = api_ins.get_status(one_id, tweet_mode='extended')\n",
    "                    json.dump(page, outfile)\n",
    "                    outfile.write('\\n')\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error for: \" + str(one_id) + \" - \" + str(e))\n",
    "                    failed_ids.append(one_id)\n",
    "    \n",
    "    # querying a single id\n",
    "    else:\n",
    "        with open(new_file_name, mode = 'w') as outfile:\n",
    "            try:\n",
    "                page = api_ins.get_status(one_id, tweet_mode='extended')\n",
    "                json.dump(page, outfile)\n",
    "                outfile.write('\\n')\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Error for: \" + str(one_id) + \" - \" + str(e))\n",
    "                failed_ids.append(one_id)\n",
    "    \n",
    "    return failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 888202515573088257 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 873697596434513921 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 872668790621863937 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 869988702071779329 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 866816280283807744 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 861769973181624320 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 845459076796616705 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 842892208864923648 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 837012587749474308 - [{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 831926988323639298 - Failed to send request: ('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\"))\n",
      "Error for: 827228250799742977 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 802247111496568832 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 775096608509886464 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 770743923962707968 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 754011816964026368 - [{'code': 144, 'message': 'No status found with that ID.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 711652651650457602 - Failed to send request: ('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 669749430875258880 - Failed to send request: ('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\"))\n",
      "That took about 42.0 mins.\n"
     ]
    }
   ],
   "source": [
    "# starting the timer\n",
    "start = timer()\n",
    "\n",
    "# passing the list of ids to the fuction fetch_and_save()\n",
    "tweet_ids = archive['tweet_id'].tolist()\n",
    "\n",
    "# fetching data 1st iteration\n",
    "test_one = fetch_and_save(tweet_ids, api)\n",
    "\n",
    "# ending the timer\n",
    "end = timer()\n",
    "\n",
    "# calculating the runtime for fetch_and_save\n",
    "print(\"That took about {} mins.\".format(round((end - start)/60, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have about 17 failed requests.\n"
     ]
    }
   ],
   "source": [
    "# no of erroneous ids\n",
    "print(\"we have about {} failed requests.\".format(len(test_one)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if test_one has duplicate ids\n",
    "assert len(test_one) == len(set(test_one))\n",
    "\n",
    "# we can see that there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 888202515573088257 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 873697596434513921 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 872668790621863937 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 869988702071779329 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 866816280283807744 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 861769973181624320 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 845459076796616705 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 842892208864923648 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 837012587749474308 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 827228250799742977 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 802247111496568832 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 775096608509886464 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 770743923962707968 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 754011816964026368 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "That took about 7.1 secs.\n"
     ]
    }
   ],
   "source": [
    "# passing this failed list to the fetch_and_save function\n",
    "\n",
    "# starting the timer\n",
    "start = timer()\n",
    "\n",
    "# fetching data 2nd iteration\n",
    "test_two = fetch_and_save(test_one, api)\n",
    "\n",
    "# ending the timer\n",
    "end = timer()\n",
    "\n",
    "# calculating the runtime for fetch_and_save\n",
    "print(\"That took about {} secs.\".format(round(end - start, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have about 14 failed requests.\n"
     ]
    }
   ],
   "source": [
    "# no of erroneous ids\n",
    "print(\"we have about {} failed requests.\".format(len(test_two)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if test_one has duplicate ids\n",
    "assert len(test_one) == len(set(test_one))\n",
    "\n",
    "# we can see that there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 888202515573088257 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 873697596434513921 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 872668790621863937 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 869988702071779329 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 866816280283807744 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 861769973181624320 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 845459076796616705 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 842892208864923648 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 837012587749474308 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 827228250799742977 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 802247111496568832 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 775096608509886464 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 770743923962707968 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 754011816964026368 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "That took about 5.8 secs.\n"
     ]
    }
   ],
   "source": [
    "# passing this failed list to the fetch_and_save function\n",
    "\n",
    "# starting the timer\n",
    "start = timer()\n",
    "\n",
    "# fetching data 2nd iteration\n",
    "test_three = fetch_and_save(test_two, api)\n",
    "\n",
    "# ending the timer\n",
    "end = timer()\n",
    "\n",
    "# calculating the runtime for fetch_and_save\n",
    "print(\"That took about {} secs.\".format(round(end - start, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if lenght of test_two equals lenght of test_three, if they are the same,\n",
    "# as per Twitter's words they don't exist any one\n",
    "\n",
    "assert len(test_two) == len(test_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"error.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for: 888202515573088257 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 873697596434513921 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 872668790621863937 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 869988702071779329 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 866816280283807744 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 861769973181624320 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 845459076796616705 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 842892208864923648 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 837012587749474308 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 827228250799742977 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 802247111496568832 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 775096608509886464 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 770743923962707968 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "Error for: 754011816964026368 - [{'code': 144, 'message': 'No status found with that ID.'}]\n",
      "That took about 5.8 secs.\n"
     ]
    }
   ],
   "source": [
    "# but to make sure, lets try it for the 4th time\n",
    "\n",
    "# starting the timer\n",
    "start = timer()\n",
    "\n",
    "# fetching data 2nd iteration\n",
    "test_four = fetch_and_save(test_three, api)\n",
    "\n",
    "# ending the timer\n",
    "end = timer()\n",
    "\n",
    "# calculating the runtime for fetch_and_save\n",
    "print(\"That took about {} secs.\".format(round(end - start, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if length of test two, three and four are the same\n",
    "assert len(test_two) == len(test_three)\n",
    "assert len(test_three) == len(test_four)\n",
    "assert len(test_two) == len(test_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<span style=\"color:red\">Important Uncomment the following lines, so that there is no error</span>***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing tweet_json files that were created for test_three and test_four - iterations for fetching data\n",
    "#files = ['tweet_json_2.txt', 'tweet_json_3.txt']\n",
    "#for file in files:\n",
    "#    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [x] **Okay, let's combine the successful jsons into one file, called the `tweet_json_master.txt`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2339, 32), (3, 27))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combing all successful jsons into one master file\n",
    "json_1 = pd.read_json('tweet_json.txt', lines = True, encoding = 'utf-8')\n",
    "json_2 = pd.read_json('tweet_json_1.txt', lines = True, encoding = 'utf-8')\n",
    "\n",
    "# total rows that we need to have in our resulting dataframe\n",
    "json_1.shape, json_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_master = pd.concat([json_1, json_2], ignore_index = True, join = 'outer', sort = True)\n",
    "json_master.to_json('tweet_json_master.txt', orient = 'records', lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [x] **Last thing to do is to tidy up our folder, let's get going.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'dataset',\n",
       " 'error.png',\n",
       " 'New Text Document.txt',\n",
       " 'README.md',\n",
       " 'wrangle_act.ipynb']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving all data files under one folder - dataset\n",
    "# removing the temporary files, that acted as placeholders\n",
    "\n",
    "# creating the folder\n",
    "folder = 'dataset'\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "# we know that our master datasets for this project are\n",
    "# 1. twitter-archive-enhanced.csv\n",
    "# 2. image-predictions.tsv\n",
    "# 3. tweet_json_master.txt\n",
    "# let us move these files\n",
    "\n",
    "# updating our files_list\n",
    "files_list[-1] = 'tweet_json_master.txt'\n",
    "\n",
    "# moving only required files\n",
    "for file in files_list:\n",
    "    if os.path.exists(file):\n",
    "        os.rename(file, folder+'/'+file)\n",
    "\n",
    "# removing the tweet_json and tweet_json_1 files as they are not required anymore\n",
    "for file in ['tweet_json.txt',\n",
    " 'tweet_json_1.txt']:\n",
    "    os.remove(file)\n",
    "    \n",
    "# lisitng the current directory\n",
    "os.listdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
